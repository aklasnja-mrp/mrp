{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from functools import reduce\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "os.chdir(\"/Users/aklasnja/2021/\")\n",
    "\n",
    "#ds = 'gov2'\n",
    "#f_topics = 'reference_tables/topics.gov2.701-850.bm25.map.dataset.csv'\n",
    "\n",
    "#ds = 'cw12b13'\n",
    "#f_topics = 'reference_tables/topics.clueweb12b13.201-300.bm25.map.dataset.csv'\n",
    "\n",
    "#ds = 'cw09b'\n",
    "#f_topics = 'reference_tables/topics.clueweb09b.1-200.bm25.map.dataset.csv'\n",
    "\n",
    "#ds = 'robust04'\n",
    "#f_topics = 'reference_tables/topics.robust04.bm25.map.dataset.csv'\n",
    "\n",
    "ds = 'msmarco'\n",
    "f_topics = 'reference_tables/topics.msmarco.bm25.map.dataset.csv'\n",
    "\n",
    "f_bm25 = os.path.join('retrievals',ds,ds+'_bm25')\n",
    "f_qrels = os.path.join('retrievals',ds,'qrels.msmarco-passage.dev-subset.txt')\n",
    "f_liwc_bm25 = os.path.join('retrievals',ds,ds+'_liwc_retrieved.csv')\n",
    "f_liwc_qrels = os.path.join('retrievals',ds,ds+'_liwc_qrels.csv')\n",
    "\n",
    "#bias calc\n",
    "at_ranklist = [5, 10, 20, 30, 50]\n",
    "save_pkl = {'tc': os.path.join('retrievals','bias',ds+'_tc.pkl'), \\\n",
    "            'bool': os.path.join('retrievals','bias',ds+'_bool.pkl'), \\\n",
    "            'tf': os.path.join('retrievals','bias',ds+'_tf.pkl')}\n",
    "save_qpkl = {'tc': os.path.join('retrievals','bias',ds+'_qrels_tc.pkl'), \\\n",
    "            'bool': os.path.join('retrievals','bias',ds+'_qrels_bool.pkl'), \\\n",
    "            'tf': os.path.join('retrievals','bias',ds+'_qrels_tf.pkl')}\n",
    "\n",
    "wordlist = 'reference_tables/wordlist_genderspecific.txt'\n",
    "\n",
    "missing_docs = os.path.join('retrievals',ds,ds+'_missing_docs')\n",
    "\n",
    "f_bias = [os.path.join('retrievals',ds,ds+'_tc_bm25.csv'),\n",
    "          os.path.join('retrievals',ds,ds+'_tf_bm25.csv'),\n",
    "          os.path.join('retrievals',ds,ds+'_bool_bm25.csv')]\n",
    "f_qbias = [os.path.join('retrievals',ds,ds+'_tc_qrels.csv'),\n",
    "          os.path.join('retrievals',ds,ds+'_tf_qrels.csv'),\n",
    "          os.path.join('retrievals',ds,ds+'_bool_qrels.csv')]\n",
    "\n",
    "#queries_gender_annotated_path = \"reference_tables/queries_gender_annotated.txt\"\n",
    "#qryids_filter = set(qryids_filter)\n",
    "\n",
    "#a reference for model classes\n",
    "ref_models = pd.read_csv('reference_tables/ref_models.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-skirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "\n",
    "d = pd.read_csv(f_topics)\n",
    "d = d.set_index('qid')\n",
    "d.rename(columns={'abstractqueryexpansion': 'query.0'}, inplace=True)\n",
    "\n",
    "#original layout - separate queries., method names\n",
    "q_cols = d[[col for col in d.columns if 'query.' in col]]\n",
    "m_cols = d[[col for col in d.columns if 'method.' in col]]\n",
    "\n",
    "qids = q_cols.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_ref = ds + '_ref.csv'\n",
    "ref = pd.read_csv(os.path.join('retrievals',ds,f_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "\n",
    "#a reference for query labels\n",
    "\n",
    "ref = pd.DataFrame(columns = ['qid','qid_text','query_no','query_text','method'])\n",
    "for i, qid in enumerate(qids):\n",
    "    no_queries = q_cols.loc[qid,].count()\n",
    "    for j in range(0, no_queries): \n",
    "        if j > 0:\n",
    "            ref = ref.append({'qid':qid, \\\n",
    "                              'qid_text':q_cols.loc[qid, 'query.0'], \\\n",
    "                              'query_no':'query.'+str(j), \\\n",
    "                              'query_text':q_cols.loc[qid, 'query.'+str(j)], \\\n",
    "                              'method':m_cols.loc[qid, 'method.'+str(j)]}, ignore_index=True)\n",
    "        else:\n",
    "            ref = ref.append({'qid':qid, \\\n",
    "                              'qid_text':q_cols.loc[qid, 'query.0'], \\\n",
    "                              'query_no':'query.'+str(j), \\\n",
    "                              'query_text':q_cols.loc[qid, 'query.'+str(j)], \\\n",
    "                              'method':'none'}, ignore_index=True)\n",
    "\n",
    "ref = ref.set_index(['method'])\n",
    "ref = ref.join(ref_models.set_index(['method']), how='left')\n",
    "\n",
    "f_ref = ds + '_ref.csv'\n",
    "ref.to_csv(os.path.join('retrievals',ds,f_ref), index=True, header=True, sep=',')\n",
    "\n",
    "#ref = ref.applymap(lambda x: x.strip() if type(x) == str else x)\n",
    "#ref = ref.query('qid_text != query_text | method == \"none\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "\n",
    "#retrieved docid lists - not sure if all documents are in the folder and not empty though\n",
    "r = pd.read_csv(f_bm25, delimiter='\\s+', names=['qid', 'query_no', 'method', 'rank', 'docid'])\n",
    "r = r.query('rank <= 50')\n",
    "r = ref.reset_index(drop=False).set_index(['qid', 'query_no', 'method']).join(r.set_index(['qid', 'query_no', 'method']), how='left')  \n",
    "r = r.reset_index(drop=False)\n",
    "\n",
    "#qrels lists\n",
    "qr = pd.read_csv(f_qrels, delimiter='\\s+', names=['qid', 'rank', 'docid', 'fill'])\n",
    "qr = qr.set_index(['qid']).join(ref.query(\"method == 'none'\").reset_index(drop=False).set_index(['qid']), how='left')\n",
    "qr = qr.reset_index(drop=False)\n",
    "\n",
    "def iter_(r, r0): \n",
    "    xr = r.groupby(r.index).mean()  \n",
    "    xr0 = r0.groupby(r0.index).mean() \n",
    "    xr0 = xr0[xr.columns]   \n",
    "    for row in xr.iloc[0:1].iterrows():\n",
    "        tmp = row[1] - xr0.loc[row[0][0]]\n",
    "        ratio = tmp.to_frame().transpose()\n",
    "        ratio['qid'] = row[0][0]\n",
    "        ratio['method'] = row[0][1]\n",
    "        ratio = ratio.set_index(['qid', 'method'])       \n",
    "    for row in xr.iloc[1:].iterrows():\n",
    "        ratio.loc[(row[0]),:] = row[1] - xr0.loc[row[0][0]]    \n",
    "    return(ratio)\n",
    "#r.to_csv(os.path.join('retrievals',ds,'ck_r.csv'), index=True, header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "\n",
    "#liwc variables for all documents\n",
    "\n",
    "l = pd.read_csv(f_liwc_bm25, delimiter=',', header='infer', engine='python')\n",
    "if (ds=='msmarco'):\n",
    "    l['docid'] = l['A'] #manually delete col containing text out of LIWC results\n",
    "    l = l.set_index(['docid']).drop(columns=['A'])\n",
    "else:\n",
    "    l['docid'] = l['Filename'].str.replace('.txt', '', regex=False)\n",
    "    l = l.set_index(['docid']).drop(columns=['Filename','Segment'])\n",
    "d = pd.read_csv(f_liwc_qrels, delimiter=',', header='infer', engine='python')\n",
    "if (ds=='msmarco'):\n",
    "    d['docid'] = d['A']\n",
    "    d = d.set_index(['docid']).drop(columns=['A'])\n",
    "else: \n",
    "    d['docid'] = d['Filename'].str.replace('.txt', '', regex=False)\n",
    "    d = d.set_index(['docid']).drop(columns=['Filename','Segment'])\n",
    "\n",
    "sel = ['female', 'male',\n",
    "       'affect', 'posemo', 'negemo', 'anx', 'anger', 'sad', \\\n",
    "       'social', 'family', 'friend', \\\n",
    "       'cogproc', 'insight', 'cause', 'discrep', 'tentat', 'certain', 'differ', \\\n",
    "       'percept', 'see', 'hear', 'feel', 'bio', 'body', 'health', 'sexual', 'ingest', \\\n",
    "       'drives', 'affiliation', 'achieve', 'power', 'reward', 'risk', \\\n",
    "       'focuspast', 'focuspresent', 'focusfuture', \\\n",
    "       'relativ', 'motion', 'space', 'time', 'work', 'leisure', 'home', 'money', 'relig', 'death'] \n",
    "#with open(os.path.join('retrievals',ds,ds+'_liwc_retrieved.pkl'), 'wb') as f:\n",
    "#    pickle.dump(l, f)\n",
    "    \n",
    "#with open(os.path.join('retrievals',ds,ds+'_liwc_qrels.pkl'), 'wb') as f:\n",
    "#    pickle.dump(d, f)\n",
    "    \n",
    "#with open(os.path.join('retrievals',ds,ds+'_liwc_retrieved.pkl'), 'rb') as f:\n",
    "    #l = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7\n",
    "\n",
    "#join to liwc results\n",
    "\n",
    "r = r.dropna().set_index(['docid'], drop=True)\n",
    "r = r.join(l[sel], how='left')\n",
    "r[sel] = r[sel].div(100)\n",
    "r = r.reset_index(drop=True)#----------rowid index\n",
    "\n",
    "qr = qr.reset_index(drop=False).set_index(['docid']).drop(columns=['rank', 'fill'])\n",
    "qr = qr.join(d[sel], how='left')\n",
    "qr = qr.set_index(['qid'], drop=True)\n",
    "qr[sel] = qr[sel].div(100) #----------qid index\n",
    "\n",
    "with open(os.path.join('retrievals',ds,ds+'_r_l.pkl'), 'wb') as f:\n",
    "    pickle.dump(r, f)\n",
    "qr.to_csv(os.path.join('retrievals',ds,'qr.csv'), index=True, header=True, sep=',')\n",
    "\n",
    "#r.isnull().sum()\n",
    "#missing_docs = r[~r.isna().any(axis=1)]['docid']\n",
    "#missing_docs = pd.DataFrame(r[r.isna().any(axis=1)]['docid'].unique())\n",
    "#missing_docs.to_csv(os.path.join('retrievals',ds,'missing_docs.txt'), index=False, header=False, sep=',')\n",
    "#qr[qr.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('retrievals',ds,ds+'_r_l.pkl'), 'rb') as f:\n",
    "    r = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-writing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8\n",
    "\n",
    "#relative: QE query vector - original query vector\n",
    "\n",
    "#reduce qids to those w/ more than original query\n",
    "exclude_qids = q_cols[q_cols['query.1'].isna()].index.tolist()\n",
    "\n",
    "#set r, r0\n",
    "ra = r[~r['qid'].isin(exclude_qids)] \n",
    "r0a = ra.query('method == \"none\"')\n",
    "\n",
    "ra.to_csv(os.path.join('retrievals',ds,'r_liwc_qe.csv'), index=True, header=True, sep=',')\n",
    "\n",
    "ratio_df = list()\n",
    "for n in at_ranklist:\n",
    "    r0_df = ra.query('rank <= @n').set_index(['qid','method']).filter(sel) #----------qid method index\n",
    "    r0a_df = r0a.query('rank <= @n').set_index(['qid']).filter(sel) #----------qid index\n",
    "    ratio = iter_(r0_df, r0a_df)\n",
    "    ratio.columns = ratio.columns + '_' + str(n)\n",
    "    ratio_df.append(ratio)\n",
    "    \n",
    "ratioa = reduce(lambda df1, df2: pd.merge(df1, df2, on=['qid','method']), ratio_df)\n",
    "ratioa.to_csv(os.path.join('retrievals',ds,'ratio_liwc_qe.csv'), index=True, header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9\n",
    "\n",
    "#relative: QE query vector - qrel vector\n",
    "\n",
    "#reduce qids to those w/ more than original query\n",
    "exclude_qids = q_cols[q_cols['query.1'].isna()].index.tolist()\n",
    "\n",
    "#reduce qids to only those w/ qrels\n",
    "exclude_qids = exclude_qids + list(set(qids).difference(set(qr.index.values)))\n",
    "\n",
    "#set r, r0\n",
    "rb = r.reset_index(drop=False)\n",
    "rb = rb[~rb['qid'].isin(exclude_qids)]\n",
    "\n",
    "r0b = qr.reset_index(drop=False) \n",
    "r0b = r0b[~r0b['qid'].isin(exclude_qids)].set_index(['qid'], drop=True).filter(sel) #----------qid index\n",
    "#r0b.to_csv(os.path.join('retrievals',ds,'r_liwc_qr.csv'), index=True, header=True, sep=',')\n",
    "\n",
    "ratio_df = list()\n",
    "for n in at_ranklist:\n",
    "    rb_df = rb.query('rank <= @n').set_index(['qid','method']).filter(sel) #----------qid method index\n",
    "    ratio = iter_(rb_df, r0b)\n",
    "    ratio.columns = ratio.columns + '_' + str(n)\n",
    "    ratio_df.append(ratio)\n",
    "\n",
    "ratiob = reduce(lambda df1, df2: pd.merge(df1, df2, on=['qid','method']), ratio_df)\n",
    "ratiob.to_csv(os.path.join('retrievals',ds,'ratio_liwc_qr.csv'), index=True, header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-actress",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "\n",
    "def calc_run_bias(experiments, docs_bias, save_pkl):   \n",
    "    runs_bias = {}\n",
    "    for exp_name in experiments:\n",
    "\n",
    "        run_path = experiments[exp_name]\n",
    "        runs_bias[exp_name] = {}\n",
    "\n",
    "        for method in save_pkl:\n",
    "            runs_bias[exp_name][method] = {}\n",
    "\n",
    "        #open ranked search results\n",
    "        with open(run_path) as fr:\n",
    "            qryid_cur = 0\n",
    "\n",
    "            for i, line in enumerate(fr):\n",
    "                #if (i % 5000000 == 0) and (i != 0):\n",
    "                    #print ('line', i)\n",
    "\n",
    "                vals = line.strip().split(' ')\n",
    "                if len(vals) == 5:\n",
    "                    qryid = vals[0]+'-'+vals[2]\n",
    "                    docid = int(vals[4])\n",
    "\n",
    "                    if qryid != qryid_cur:\n",
    "                        for method in save_pkl:\n",
    "                            runs_bias[exp_name][method][qryid] = []\n",
    "                        qryid_cur = qryid\n",
    "\n",
    "                    for method in save_pkl:\n",
    "                        try:\n",
    "                            runs_bias[exp_name][method][qryid].append(docs_bias[method][docid])   \n",
    "                        except:\n",
    "                            print(docid)\n",
    "                            runs_bias[exp_name][method][qryid].append(None) \n",
    "                            with open(missing_docs, 'a') as miss:\n",
    "                                miss.write(f'{docid}\\n')\n",
    "                            continue\n",
    "\n",
    "        for method in save_pkl:\n",
    "            print (method, len(runs_bias[exp_name][method].keys()))\n",
    "    return runs_bias\n",
    "\n",
    "def calc_RaB_q(bias_list, at_rank):\n",
    "    bias_val = np.mean([x[0] for x in bias_list[:at_rank]])\n",
    "    bias_feml_val = np.mean([x[1] for x in bias_list[:at_rank]])\n",
    "    bias_male_val = np.mean([x[2] for x in bias_list[:at_rank]])\n",
    "    \n",
    "    return bias_val, bias_feml_val, bias_male_val\n",
    "         \n",
    "def calc_ARaB_q(bias_list, at_rank):\n",
    "    vals = []\n",
    "    feml_vals = []\n",
    "    male_vals = []\n",
    "    for t in range(at_rank):\n",
    "        if len(bias_list) >= t+1:\n",
    "            val_RaB, feml_val_RaB, male_val_RaB = calc_RaB_q(bias_list, t+1)\n",
    "            vals.append(val_RaB)\n",
    "            feml_vals.append(feml_val_RaB)\n",
    "            male_vals.append(male_val_RaB)\n",
    "            \n",
    "    bias_val = np.mean(vals)\n",
    "    bias_feml_val = np.mean(feml_vals)\n",
    "    bias_male_val = np.mean(male_vals)\n",
    "    \n",
    "    return bias_val, bias_feml_val, bias_male_val\n",
    "\n",
    "def calc_qry_bias(experiments, docs_bias, runs_bias, at_ranklist, ref):\n",
    "    qry_bias_RaB = {}\n",
    "    qry_bias_ARaB = {}\n",
    "    for exp_name in experiments:\n",
    "        qry_bias_RaB[exp_name] = {}\n",
    "        qry_bias_ARaB[exp_name] = {}\n",
    "\n",
    "        for method in docs_bias:\n",
    "            qry_bias_RaB[exp_name][method] = {}\n",
    "            qry_bias_ARaB[exp_name][method] = {}\n",
    "\n",
    "            for at_rank in at_ranklist:\n",
    "                qry_bias_RaB[exp_name][method][at_rank] = {}\n",
    "                qry_bias_ARaB[exp_name][method][at_rank] = {}\n",
    "\n",
    "                for qry_id in runs_bias[exp_name][method]:\n",
    "                    qry_bias_RaB[exp_name][method][at_rank][qry_id] = calc_RaB_q(runs_bias[exp_name][method][qry_id], at_rank)\n",
    "                    qry_bias_ARaB[exp_name][method][at_rank][qry_id] = calc_ARaB_q(runs_bias[exp_name][method][qry_id], at_rank)\n",
    "\n",
    "    experiment = list(experiments.keys())\n",
    "    bias = list(docs_bias.keys())\n",
    "    print(experiment)\n",
    "    print(bias)\n",
    "\n",
    "    bias_df = list()\n",
    "    for i in experiment:\n",
    "        for j in bias:\n",
    "            df = pd.DataFrame(qry_bias_RaB[i][j], columns=list(qry_bias_RaB[i][j].keys())).reset_index()\n",
    "            df[['qid', 'method']] = df['index'].str.split('-', 1, expand=True)\n",
    "            df = df.drop(columns=['index']).set_index(['qid', 'method'])\n",
    "            for l in df.columns:\n",
    "                df['bias_'+str(l)], df['feml_'+str(l)], df['male_'+str(l)] = df[l].str\n",
    "                df = df.drop(columns=[l])\n",
    "            df.columns = j + '_RaB_' + df.columns\n",
    "            out = df\n",
    "            df = pd.DataFrame(qry_bias_ARaB[i][j], columns=list(qry_bias_ARaB[i][j].keys())).reset_index()\n",
    "            df[['qid', 'method']] = df['index'].str.split('-', 1, expand=True)\n",
    "            df = df.drop(columns=['index']).set_index(['qid', 'method'])\n",
    "            for l in df.columns:\n",
    "                df['bias_'+str(l)], df['feml_'+str(l)], df['male_'+str(l)] = df[l].str\n",
    "                df = df.drop(columns=[l])\n",
    "            df.columns = j + '_ARaB_' + df.columns\n",
    "            bias_df.append(out.join(df, how='outer'))\n",
    "        \n",
    "    #bias output\n",
    "    b = reduce(lambda df1, df2: pd.merge(df1, df2, on=['qid','method']), bias_df)\n",
    "    ref = ref.reset_index(drop=False).set_index(['qid','method'], drop=True)\n",
    "    b.index = b.index.set_levels(b.index.levels[0].astype(int), level=0)\n",
    "    b = b.join(ref, how='left')\n",
    "    return b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11\n",
    "\n",
    "# runs bias \n",
    "\n",
    "docs_bias = {}\n",
    "for method in save_pkl:\n",
    "    print (method)\n",
    "    with open(save_pkl[method], 'rb') as fr:\n",
    "        docs_bias[method] = pickle.load(fr)\n",
    "\n",
    "experiments = {'bm25': f_bm25}\n",
    "runs_bias = calc_run_bias(experiments, docs_bias, save_pkl)\n",
    "\n",
    "b = calc_qry_bias(experiments, docs_bias, runs_bias, at_ranklist, ref)\n",
    "b.to_csv(os.path.join('retrievals',ds,ds+'_bias_retrieved.csv'), index=True, header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-thailand",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12\n",
    "\n",
    "#relative: QE query vector - original query vector\n",
    "\n",
    "#reduce qids to those w/ more than original query\n",
    "exclude_qids = q_cols[q_cols['query.1'].isna()].index.tolist()\n",
    "\n",
    "b = b.reset_index(drop=False)\n",
    "ba = b[~b['qid'].isin(exclude_qids)] \n",
    "\n",
    "ba.to_csv(os.path.join('retrievals',ds,'r_bias_qe.csv'), index=True, header=True, sep=',')\n",
    "\n",
    "#set r, r0\n",
    "b0a = ba.query('method == \"none\"').set_index(['qid'], drop=True).select_dtypes(['number']) #----------qid index\n",
    "ba = ba.set_index(['qid','method'], drop=True).select_dtypes(['number']) #----------qid method index\n",
    "\n",
    "ratioa = iter_(ba, b0a)\n",
    "ratioa.to_csv(os.path.join('retrievals',ds,'ratio_bias_qe.csv'), index=True, header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13\n",
    "\n",
    "def calc_RaB_q_qrels(bias_list):\n",
    "    bias_val = np.mean([x[0] for x in bias_list])\n",
    "    bias_feml_val = np.mean([x[1] for x in bias_list])\n",
    "    bias_male_val = np.mean([x[2] for x in bias_list])\n",
    "    \n",
    "    return bias_val, bias_feml_val, bias_male_val\n",
    "\n",
    "def calc_run_bias_qrels(experiments, docs_bias, save_pkl):     \n",
    "    runs_bias = {}\n",
    "    for exp_name in experiments:\n",
    "\n",
    "        run_path = experiments[exp_name]\n",
    "        runs_bias[exp_name] = {}\n",
    "\n",
    "        for method in save_pkl:\n",
    "            runs_bias[exp_name][method] = {}\n",
    "\n",
    "        #open ranked search results\n",
    "        with open(run_path) as fr:\n",
    "            qryid_cur = 0\n",
    "\n",
    "            for i, line in enumerate(fr):\n",
    "                if (i % 5000000 == 0) and (i != 0):\n",
    "                    print ('line', i)\n",
    "\n",
    "                vals = line.strip().split(' ')\n",
    "                if len(vals) == 4:\n",
    "                    qryid = vals[0]\n",
    "                    docid = vals[2]\n",
    "\n",
    "                    if qryid != qryid_cur:\n",
    "                        for method in save_pkl:\n",
    "                            runs_bias[exp_name][method][qryid] = []\n",
    "                        qryid_cur = qryid\n",
    "\n",
    "                    for method in save_pkl:\n",
    "                        runs_bias[exp_name][method][qryid].append(docs_bias[method][docid])    \n",
    "\n",
    "        for method in save_pkl:\n",
    "            print (method, len(runs_bias[exp_name][method].keys()))\n",
    "    return runs_bias\n",
    "\n",
    "def calc_qry_bias_qrels(experiments, docs_bias, runs_bias, ref):\n",
    "    qry_bias_RaB = {}\n",
    "\n",
    "    for exp_name in experiments:\n",
    "        qry_bias_RaB[exp_name] = {}\n",
    "\n",
    "        for method in docs_bias:\n",
    "            qry_bias_RaB[exp_name][method] = {}\n",
    "\n",
    "            for qry_id in runs_bias[exp_name][method]:\n",
    "                qry_bias_RaB[exp_name][method][qry_id] = calc_RaB_q_qrels(runs_bias[exp_name][method][qry_id])\n",
    "\n",
    "    experiment = list(experiments.keys())\n",
    "    bias = list(docs_bias.keys())\n",
    "    print(experiment)\n",
    "    print(bias)\n",
    "    \n",
    "    bias_df = list()\n",
    "    for i in experiment:\n",
    "        for j in bias:\n",
    "            df = pd.DataFrame(qry_bias_RaB[i][j], columns=list(qry_bias_RaB[i][j].keys())).reset_index()\n",
    "            df = df.T\n",
    "            df = df.rename_axis(\"qid\").drop(index='index')\n",
    "            df.columns = [j+'_RaB_bias', j+'_RaB_feml', j+'_RaB_male'] \n",
    "            bias_df.append(df)\n",
    "        \n",
    "    #bias output\n",
    "    b = reduce(lambda df1, df2: pd.merge(df1, df2, on=['qid']), bias_df)\n",
    "    ref = ref.reset_index(drop=False).set_index(['qid'], drop=True).query('method == \"none\"')\n",
    "    b.index = b.index.astype(int)\n",
    "    b = b.join(ref, how='left')\n",
    "    return b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14   \n",
    "\n",
    "#saved document bias values\n",
    "docs_bias = {}\n",
    "for method in save_qpkl:\n",
    "    print (method)\n",
    "    with open(save_qpkl[method], 'rb') as fr:\n",
    "        docs_bias[method] = pickle.load(fr)\n",
    "\n",
    "experiments = {'qrels': f_qrels}\n",
    "runs_bias = calc_run_bias_qrels(experiments, docs_bias, save_qpkl)\n",
    "\n",
    "b0 = calc_qry_bias_qrels(experiments, docs_bias, runs_bias, ref)\n",
    "b0.to_csv(os.path.join('retrievals',ds,ds+'_bias_qrels.csv'), index=True, header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14\n",
    "\n",
    "#relative: QE query vector - qrel vector\n",
    "\n",
    "#reduce qids to those w/ more than original query\n",
    "exclude_qids = q_cols[q_cols['query.1'].isna()].index.tolist()\n",
    "\n",
    "#reduce qids to only those w/ qrels\n",
    "exclude_qids = exclude_qids + list(set(qids).difference(set(qr.index.values)))\n",
    "\n",
    "#set r, r0\n",
    "bb = b[~b['qid'].isin(exclude_qids)] \n",
    "bb = bb.set_index(['qid','method']).select_dtypes(['number']).filter(like='_RaB',axis=1) #----------qid method index\n",
    "\n",
    "bb.to_csv(os.path.join('retrievals',ds,'r_bias_qr.csv'), index=True, header=True, sep=',')\n",
    "\n",
    "b0_df = list()\n",
    "for i in at_ranklist:   \n",
    "    df = b0.select_dtypes(['number'])\n",
    "    df.columns = df.columns + '_' + str(i)\n",
    "    b0_df.append(df)\n",
    "b0b = reduce(lambda df1, df2: pd.merge(df1, df2, on=['qid']), b0_df) #----------qid index\n",
    "b0b = b0b[bb.columns]\n",
    "\n",
    "ratiob = iter_(bb, b0b)\n",
    "ratiob.to_csv(os.path.join('retrievals',ds,'ratio_bias_qr.csv'), index=True, header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-juvenile",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
